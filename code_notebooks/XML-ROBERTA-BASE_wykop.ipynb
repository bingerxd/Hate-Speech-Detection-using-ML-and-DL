{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5328,
     "status": "ok",
     "timestamp": 1748633286819,
     "user": {
      "displayName": "Cweluch",
      "userId": "18293133240002078186"
     },
     "user_tz": -120
    },
    "id": "rFO64Dw9dXBO"
   },
   "outputs": [],
   "source": [
    "!pip install transformers torch scikit-learn matplotlib seaborn tqdm --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "51AH9AuXdZQU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix,\n",
    "    classification_report, roc_curve\n",
    ")\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, get_scheduler\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HOdjFyMieDXf"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_NAME = \"xlm-roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LinbjS74dVgl"
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encodings = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {key: val.squeeze(0) for key, val in encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ANk_bry1eVsi"
   },
   "outputs": [],
   "source": [
    "def load_and_split_data(data_path, tokenizer, max_len=64, test_size=0.2, random_state=42):\n",
    "    df = pd.read_csv(data_path)\n",
    "    train_df, test_df = train_test_split(df, test_size=test_size, stratify=df['Class'], random_state=random_state)\n",
    "\n",
    "    train_dataset = TextDataset(train_df['Text'].tolist(), train_df['Class'].tolist(), tokenizer, max_len)\n",
    "    test_dataset = TextDataset(test_df['Text'].tolist(), test_df['Class'].tolist(), tokenizer, max_len)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_iwajsCeaUz"
   },
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.transformer = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(self.transformer.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = output.last_hidden_state[:, 0]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        return self.classifier(pooled_output).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XxEDf4Tnev4O"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_loader, test_loader, model_name=\"xlm-roberta-base\", save_dir=\"results/xlm-roberta\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    model = TransformerClassifier(model_name).to(DEVICE)\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    num_training_steps = len(train_loader) * 6\n",
    "    scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    EPOCHS = 6\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1} Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                input_ids = batch['input_ids'].to(DEVICE)\n",
    "                attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "                labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "                logits = model(input_ids, attention_mask)\n",
    "                loss = criterion(logits, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(test_loader)\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, \"best_model.pt\"))\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= 2:\n",
    "                print(\"⏹️ Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(save_dir, \"best_model.pt\")))\n",
    "    model.eval()\n",
    "    all_preds, all_probs, all_labels = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > 0.5).int()\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-score:  {f1:.4f}\")\n",
    "    print(f\"ROC AUC:   {auc:.4f}\")\n",
    "    print(classification_report(all_labels, all_preds, zero_division=0))\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure()\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(\"Confusion Matrix for RoBERTa - The Best Variant\")\n",
    "    plt.savefig(os.path.join(save_dir, \"confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {auc:.4f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.title(\"ROC Curve for RoBERTa - The Best Varianl\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, \"roc_curve.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FluKYWcDfQNm"
   },
   "outputs": [],
   "source": [
    "def run_pipeline_xlmr_singlefile(data_path, max_len=256):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    train_loader, test_loader = load_and_split_data(data_path, tokenizer, max_len)\n",
    "    train_and_evaluate(train_loader, test_loader, model_name=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1748637472604,
     "user": {
      "displayName": "Cweluch",
      "userId": "18293133240002078186"
     },
     "user_tz": -120
    },
    "id": "305u1S-XBoWp",
    "outputId": "4db885bb-a6bc-464f-8b32-71d7fe588768"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_2b80327b-8a04-4bb1-a408-7d3de01ec00e\", \"best_model.pt\", 1112262919)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download('/content/results/xlm-roberta/best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2223513,
     "status": "ok",
     "timestamp": 1748620541821,
     "user": {
      "displayName": "Patryk Zabawa",
      "userId": "07018757029536088376"
     },
     "user_tz": -120
    },
    "id": "o_8hn6E3rg9X",
    "outputId": "f0570562-8cf1-4bed-a2ab-da5ac7343f77"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1200/1200 [14:24<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.3340\n",
      "Validation Loss: 0.2266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1200/1200 [14:23<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.2048\n",
      "Validation Loss: 0.2235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1200/1200 [14:23<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.1440\n",
      "Validation Loss: 0.2349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1200/1200 [14:22<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.0972\n",
      "Validation Loss: 0.2636\n",
      "⏹️ Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 300/300 [01:00<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9137\n",
      "Precision: 0.9020\n",
      "Recall:    0.9283\n",
      "F1-score:  0.9150\n",
      "ROC AUC:   0.9733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.90      0.91      2400\n",
      "         1.0       0.90      0.93      0.91      2400\n",
      "\n",
      "    accuracy                           0.91      4800\n",
      "   macro avg       0.91      0.91      0.91      4800\n",
      "weighted avg       0.91      0.91      0.91      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_pipeline_xlmr_singlefile(\"BAN-PL_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 794,
     "referenced_widgets": [
      "a83086f08d624b79a15d7573e67c8319",
      "609e4422d4d34329a0884965872e141e",
      "800f03eb8a6f426b80d942fffa87990b",
      "ec849a6703da4099adc12bda5825f988",
      "c5b6c3f7ca6149bba76dddbba3872e08"
     ]
    },
    "executionInfo": {
     "elapsed": 3010104,
     "status": "ok",
     "timestamp": 1748633280904,
     "user": {
      "displayName": "Cweluch",
      "userId": "18293133240002078186"
     },
     "user_tz": -120
    },
    "id": "rruiJMMQo5kU",
    "outputId": "8e20af2b-60c2-49b8-e1db-7755c8ccec35"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83086f08d624b79a15d7573e67c8319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609e4422d4d34329a0884965872e141e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800f03eb8a6f426b80d942fffa87990b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec849a6703da4099adc12bda5825f988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b6c3f7ca6149bba76dddbba3872e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1199/1199 [13:52<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.4003\n",
      "Validation Loss: 0.3144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1199/1199 [13:59<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.2695\n",
      "Validation Loss: 0.2843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1199/1199 [14:00<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.2015\n",
      "Validation Loss: 0.3179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1199/1199 [13:59<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.1450\n",
      "Validation Loss: 0.3629\n",
      "⏹️ Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 300/300 [00:56<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8903\n",
      "Precision: 0.9006\n",
      "Recall:    0.8773\n",
      "F1-score:  0.8888\n",
      "ROC AUC:   0.9556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.90      0.89      2399\n",
      "         1.0       0.90      0.88      0.89      2396\n",
      "\n",
      "    accuracy                           0.89      4795\n",
      "   macro avg       0.89      0.89      0.89      4795\n",
      "weighted avg       0.89      0.89      0.89      4795\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_pipeline_xlmr_singlefile(\"BAN-PL_light.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3633819,
     "status": "ok",
     "timestamp": 1748637410621,
     "user": {
      "displayName": "Cweluch",
      "userId": "18293133240002078186"
     },
     "user_tz": -120
    },
    "id": "51jsNZRso-Zh",
    "outputId": "821ef21f-7524-48d2-a08d-39f4e33900ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1197/1197 [13:49<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.4445\n",
      "Validation Loss: 0.3671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1197/1197 [13:54<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.3083\n",
      "Validation Loss: 0.3144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1197/1197 [13:53<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.2532\n",
      "Validation Loss: 0.3236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1197/1197 [13:53<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.2025\n",
      "Validation Loss: 0.3437\n",
      "⏹️ Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 300/300 [00:56<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8644\n",
      "Precision: 0.8598\n",
      "Recall:    0.8709\n",
      "F1-score:  0.8653\n",
      "ROC AUC:   0.9412\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.86      0.86      2391\n",
      "         1.0       0.86      0.87      0.87      2394\n",
      "\n",
      "    accuracy                           0.86      4785\n",
      "   macro avg       0.86      0.86      0.86      4785\n",
      "weighted avg       0.86      0.86      0.86      4785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_pipeline_xlmr_singlefile(\"BAN-PL_full.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
